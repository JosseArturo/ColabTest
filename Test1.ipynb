{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosseArturo/ColabTest/blob/master/Test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8c0jAmG0aYSq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2YtesAfiVg4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80787bd7-392b-4be5-ba97-65ab3737dff0"
      },
      "cell_type": "code",
      "source": [
        "# Create TensorFlow object called tensor\n",
        "hello_constant = tf.constant('Hello World!')\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # Run the tf.constant operation in the session\n",
        "    output = sess.run(hello_constant)\n",
        "    print(output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello World!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dF4SLN3dlNh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25dc6b91-cee8-4286-e082-affba6e5287b"
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.string)\n",
        "y = tf.placeholder(tf.int32)\n",
        "z = tf.placeholder(tf.float32)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    output = sess.run(x, feed_dict={x: 'Test String', y: 123, z: 45.67})\n",
        "    print (output)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test String\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XGavBpyymwc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9632bbb-5587-424e-9383-847e47df3f6f"
      },
      "cell_type": "code",
      "source": [
        " \n",
        "x = tf.constant(10)\n",
        "y = tf.constant(2)\n",
        "z = tf.subtract(tf.divide(x,y),tf.cast(tf.constant(1),tf.float64))\n",
        " \n",
        "with tf.Session() as sess:\n",
        "    output = sess.run(z)\n",
        "    print(output)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XNJ6z44u9uIj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##############################\n",
        "#Logistic Classifier\n",
        "##############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n0fW0M5Anr3Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Logistic Classifier\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_weights(n_features, n_labels):\n",
        "    \"\"\"\n",
        "    Return TensorFlow weights\n",
        "    :param n_features: Number of features\n",
        "    :param n_labels: Number of labels\n",
        "    :return: TensorFlow weights\n",
        "    \"\"\"\n",
        "    get_weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
        "    # TODO: Return weights\n",
        "    return get_weights\n",
        "\n",
        "\n",
        "def get_biases(n_labels):\n",
        "    \"\"\"\n",
        "    Return TensorFlow bias\n",
        "    :param n_labels: Number of labels\n",
        "    :return: TensorFlow bias\n",
        "    \"\"\"\n",
        "    get_biases = tf.Variable(tf.zeros(n_labels))\n",
        "    # TODO: Return biases\n",
        "    return get_biases\n",
        "\n",
        "\n",
        "def linear(input, w, b):\n",
        "    \"\"\"\n",
        "    Return linear function in TensorFlow\n",
        "    :param input: TensorFlow input\n",
        "    :param w: TensorFlow weights\n",
        "    :param b: TensorFlow biases\n",
        "    :return: TensorFlow linear function\n",
        "    \"\"\"\n",
        "    y=  tf.add(tf.matmul(input,w),b)\n",
        "    # TODO: Linear Function (xW + b)\n",
        "    \n",
        "    return y\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPd2fWE76hcj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6f07313b-406d-46f2-fcc0-d02f1db6c06b"
      },
      "cell_type": "code",
      "source": [
        "mport tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from test import *\n",
        "\n",
        "def mnist_features_labels(n_labels):\n",
        "    \"\"\"\n",
        "    Gets the first <n> labels from the MNIST dataset\n",
        "    :param n_labels: Number of labels to use\n",
        "    :return: Tuple of feature list and label list\n",
        "    \"\"\"\n",
        "    mnist_features = []\n",
        "    mnist_labels = []\n",
        "\n",
        "    mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
        "\n",
        "    # In order to make quizzes run faster, we're only looking at 10000 images\n",
        "    for mnist_feature, mnist_label in zip(*mnist.train.next_batch(10000)):\n",
        "\n",
        "        # Add features and labels if it's for the first <n>th labels\n",
        "        if mnist_label[:n_labels].any():\n",
        "            mnist_features.append(mnist_feature)\n",
        "            mnist_labels.append(mnist_label[:n_labels])\n",
        "\n",
        "    return mnist_features, mnist_labels\n",
        "\n",
        "\n",
        "# Number of features (28*28 image is 784 features)\n",
        "n_features = 784\n",
        "# Number of labels\n",
        "n_labels = 3\n",
        "\n",
        "# Features and Labels\n",
        "features = tf.placeholder(tf.float32)\n",
        "labels = tf.placeholder(tf.float32)\n",
        "\n",
        "# Weights and Biases\n",
        "w = get_weights(n_features, n_labels)\n",
        "b = get_biases(n_labels)\n",
        "\n",
        "# Linear Function xW + b\n",
        "logits = linear(features, w, b)\n",
        "\n",
        "# Training data\n",
        "train_features, train_labels = mnist_features_labels(n_labels)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "with tf.Session() as session:\n",
        "    # TODO: Initialize session variables\n",
        "    session.run(init)\n",
        "    # Softmax\n",
        "    prediction = tf.nn.softmax(logits)\n",
        "\n",
        "    # Cross entropy\n",
        "    # This quantifies how far off the predictions were.\n",
        "    # You'll learn more about this in future lessons.\n",
        "    cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
        "\n",
        "    # Training loss\n",
        "    # You'll learn more about this in future lessons.\n",
        "    loss = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "    # Rate at which the weights are changed\n",
        "    # You'll learn more about this in future lessons.\n",
        "    learning_rate = 0.08\n",
        "\n",
        "    # Gradient Descent\n",
        "    # This is the method used to train the model\n",
        "    # You'll learn more about this in future lessons.\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "    # Run optimizer and get loss\n",
        "    _, l = session.run(\n",
        "        [optimizer, loss],\n",
        "        feed_dict={features: train_features, labels: train_labels})\n",
        "\n",
        "# Print loss\n",
        "print('Loss: {}'.format(l))\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n",
            "Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Loss: 15.78938102722168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NJqB7_yf9ZsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7b9fc2fd-3ac0-48e2-c8ff-503b874227d3"
      },
      "cell_type": "code",
      "source": [
        "##Grader done by Udacity\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework.errors import FailedPreconditionError\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def is_weights_good(w):\n",
        "    w_answer = [[-0.01811021,  0.51838213],\n",
        " [ 0.05832403, -0.48847285],\n",
        " [-0.37598562, -0.7711397 ],\n",
        " [-0.5922465, -0.3118519 ],\n",
        " [ 0.21055079, -1.1010232 ]] \n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        w_result = sess.run(w)\n",
        "      \n",
        "    return np.allclose(w_answer, w_result)\n",
        "\n",
        "\n",
        "def is_biases_good(b):\n",
        "    b_answer = [0.0, 0.0]\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        b_result = sess.run(b)\n",
        "        \n",
        "    return np.array_equal(b_answer, b_result)\n",
        "\n",
        "\n",
        "def is_linear_good(l, test_input):\n",
        "    \n",
        "    logits_answer = [[-2.34565091, -9.52450562],[-8.03849602, -9.28480148]]\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        logits_result = sess.run(l, feed_dict={test_input: [[1,2,3,4,5], [6,7,8,9,0]]})\n",
        "        \n",
        "    return np.allclose(logits_answer, logits_result)\n",
        "\n",
        "def get_result(get_weights, get_biases, linear):\n",
        "    result = {\n",
        "        'correct': False,\n",
        "        'feedback': 'That\\'s the wrong answer.',\n",
        "        'comment': ''}\n",
        "\n",
        "    tf.set_random_seed(123456)\n",
        "    \n",
        "    n_features = 5\n",
        "    n_labels = 2\n",
        "    test_input = tf.placeholder(tf.float32)\n",
        "    \n",
        "    weights = get_weights(n_features, n_labels)\n",
        "    biases = get_biases(n_labels)\n",
        "    lin = linear(test_input, weights, biases)\n",
        "\n",
        "    if not isinstance(weights, tf.Variable):\n",
        "        result['feedback'] = 'Function weights not returning tf.Variable type.'\n",
        "        result['comment'] = 'Use the tf.Variable function.'\n",
        "    elif not isinstance(biases, tf.Variable):\n",
        "        result['feedback'] = 'Function biases not returning tf.Variable type.'\n",
        "        result['comment'] = 'Use the tf.Variable function.'\n",
        "    elif weights.get_shape() != (n_features, n_labels):\n",
        "        result['feedback'] = 'Function weights is returning the wrong shape.'\n",
        "    elif biases.get_shape() != n_labels:\n",
        "        result['feedback'] = 'Function biases is returning the wrong shape.'\n",
        "    elif not is_weights_good(weights):\n",
        "        result['feedback'] = 'Function weights isn\\'t correct.'\n",
        "    elif not is_biases_good(biases):\n",
        "        result['feedback'] = 'Function biases isn\\'t correct.'\n",
        "    elif not is_linear_good(lin, test_input):\n",
        "        import pdb;pdb.set_trace()\n",
        "        result['feedback'] = 'Function linear isn\\'t correct.'\n",
        "    else:\n",
        "        try:\n",
        "            std_out = sys.stdout\n",
        "            f = open(os.devnull, 'w')\n",
        "            sys.stdout = f\n",
        "        \n",
        "        except FailedPreconditionError as err:\n",
        "            if err.message.startswith('Attempting to use uninitialized value Variable'):\n",
        "                result['feedback'] = 'At least one variable is not initialized.'\n",
        "            else:\n",
        "                raise err\n",
        "        else:\n",
        "            result['correct'] = True\n",
        "            result['feedback'] = 'You got it!  That\\'s the correct answer.'\n",
        "        finally:\n",
        "            sys.stdout = std_out\n",
        "    return result\n",
        "\n",
        "def run_grader(get_weights, get_biases, linear):\n",
        "    \n",
        "    try:\n",
        "    # Get grade result information\n",
        "        result = get_result(get_weights, get_biases, linear)\n",
        "    except Exception as err:\n",
        "        # Default error result\n",
        "        result = {\n",
        "            'correct': False,\n",
        "            'feedback': 'Something went wrong with your submission:',\n",
        "            'comment': str(err)}\n",
        "\n",
        "    feedback = result.get('feedback')\n",
        "    comment = result.get('comment')\n",
        "\n",
        "    print(f\"{feedback}\\n{comment}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_grader(get_weights, get_biases, linear)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function weights isn't correct.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BaCqJvDt6n8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0a0244ab-a8a9-4bb8-c2a9-555ae7a723e8"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "### DON'T MODIFY ANYTHING BELOW ###\n",
        "### Be sure to run all cells above before running this cell ###\n",
        "#import grader\n",
        "\n",
        "try:\n",
        "    run_grader(get_weights, get_biases, linear)\n",
        "except Exception as err:\n",
        "    print(str(err))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function weights isn't correct.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YM4M2_t29ypJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##############################\n",
        "#Logistic Classifier ends\n",
        "##############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "klc7atrO9Y65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##############################\n",
        "#Softmax function\n",
        "##############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3BUScLk6q4x4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b27d244a-39fc-4177-aaab-afcb10d2282f"
      },
      "cell_type": "code",
      "source": [
        "# Solution is available in the other \"solution.py\" tab\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    # TODO: Compute and return softmax(x)\n",
        "    return np.exp(x)/np.sum(np.exp(x))\n",
        "    \n",
        "logits = [3.0, 1.0, 0.2]\n",
        "print(softmax(logits))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.8360188  0.11314284 0.05083836]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nJEKzT-JtfkS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##############################\n",
        "#Softmax function TENSOR\n",
        "##############################\n",
        "\n",
        "[0.6590012 0.242433  0.0985659]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "02n4xpqVuLSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95737fc8-b97a-420f-d22d-659db0e877e0"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def run():\n",
        "    output = None\n",
        "    logit_data = [2.0, 1.0, 0.1]\n",
        "    logits = tf.constant(logit_data)\n",
        "    #logits = tf.placeholder(tf.float32)\n",
        "    \n",
        "    # TODO: Calculate the softmax of the logits\n",
        "    softmax = tf.nn.softmax(logits)\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        pass\n",
        "        # TODO: Feed in the logit data\n",
        "        output = sess.run(softmax, feed_dict={logits:logit_data})   \n",
        "   \n",
        "    return output\n",
        "  \n",
        "out = run()\n",
        "print (out)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6590012 0.242433  0.0985659]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qs2uYu2i4SEz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##############################\n",
        "#Mini Batch\n",
        "##############################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aN4sOyws-qG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "def batches(batch_size, features, labels):\n",
        "    \"\"\"\n",
        "    Create batches of features and labels\n",
        "    :param batch_size: The batch size\n",
        "    :param features: List of features\n",
        "    :param labels: List of labels\n",
        "    :return: Batches of (Features, Labels)\n",
        "    \"\"\"\n",
        "    assert len(features) == len(labels)\n",
        "    outout_batches = []\n",
        "    \n",
        "    sample_size = len(features)\n",
        "    for start_i in range(0, sample_size, batch_size):\n",
        "        end_i = start_i + batch_size\n",
        "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
        "        outout_batches.append(batch)\n",
        "        \n",
        "    return outout_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BGBdB3ln4Sxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c64d1c6a-4509-4a8c-95d8-a6f1295f104b"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "learning_rate = 0.05\n",
        "n_input = 784  # MNIST data input (img shape: 28*28)\n",
        "n_classes = 10  # MNIST total classes (0-9 digits)\n",
        "\n",
        "# Import MNIST data\n",
        "mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
        "\n",
        "# The features are already scaled and the data is shuffled\n",
        "train_features = mnist.train.images\n",
        "test_features = mnist.test.images\n",
        "\n",
        "train_labels = mnist.train.labels.astype(np.float32)\n",
        "test_labels = mnist.test.labels.astype(np.float32)\n",
        "\n",
        "# Features and Labels\n",
        "features = tf.placeholder(tf.float32, [None, n_input])\n",
        "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
        "\n",
        "# Weights & bias\n",
        "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
        "bias = tf.Variable(tf.random_normal([n_classes]))\n",
        "\n",
        "# Logits - xW + b\n",
        "logits = tf.add(tf.matmul(features, weights), bias)\n",
        "\n",
        "# Define loss and optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n",
            "Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DgCLrU_Y-d6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5957dd29-1eb5-4478-8df4-c6324263cc87"
      },
      "cell_type": "code",
      "source": [
        "# TODO: Set batch size\n",
        "batch_size = 32\n",
        "assert batch_size is not None, 'You must set the batch size'\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(20): #Added to get more iteractions an improve gradient retropropagation\n",
        "        # TODO: Train optimizer on all batches\n",
        "        for batch_features, batch_labels in batches(batch_size, train_features, train_labels):\n",
        "        # for batch_features, batch_labels in ______\n",
        "            sess.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
        "\n",
        "    # Calculate accuracy for test dataset\n",
        "    test_accuracy = sess.run(accuracy, feed_dict={features: test_features, labels: test_labels})\n",
        "\n",
        "print('Test Accuracy: {}'.format(test_accuracy))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8982999920845032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-cRQ4RU5_kPQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}