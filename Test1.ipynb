{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosseArturo/ColabTest/blob/master/Test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8c0jAmG0aYSq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2YtesAfiVg4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80787bd7-392b-4be5-ba97-65ab3737dff0"
      },
      "cell_type": "code",
      "source": [
        "# Create TensorFlow object called tensor\n",
        "hello_constant = tf.constant('Hello World!')\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # Run the tf.constant operation in the session\n",
        "    output = sess.run(hello_constant)\n",
        "    print(output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Hello World!'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dF4SLN3dlNh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25dc6b91-cee8-4286-e082-affba6e5287b"
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.string)\n",
        "y = tf.placeholder(tf.int32)\n",
        "z = tf.placeholder(tf.float32)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    output = sess.run(x, feed_dict={x: 'Test String', y: 123, z: 45.67})\n",
        "    print (output)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test String\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XGavBpyymwc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9632bbb-5587-424e-9383-847e47df3f6f"
      },
      "cell_type": "code",
      "source": [
        " \n",
        "x = tf.constant(10)\n",
        "y = tf.constant(2)\n",
        "z = tf.subtract(tf.divide(x,y),tf.cast(tf.constant(1),tf.float64))\n",
        " \n",
        "with tf.Session() as sess:\n",
        "    output = sess.run(z)\n",
        "    print(output)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XNJ6z44u9uIj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##############################\n",
        "#Logistic Classifier\n",
        "##############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n0fW0M5Anr3Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Logistic Classifier\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_weights(n_features, n_labels):\n",
        "    \"\"\"\n",
        "    Return TensorFlow weights\n",
        "    :param n_features: Number of features\n",
        "    :param n_labels: Number of labels\n",
        "    :return: TensorFlow weights\n",
        "    \"\"\"\n",
        "    get_weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
        "    # TODO: Return weights\n",
        "    return get_weights\n",
        "\n",
        "\n",
        "def get_biases(n_labels):\n",
        "    \"\"\"\n",
        "    Return TensorFlow bias\n",
        "    :param n_labels: Number of labels\n",
        "    :return: TensorFlow bias\n",
        "    \"\"\"\n",
        "    get_biases = tf.Variable(tf.zeros(n_labels))\n",
        "    # TODO: Return biases\n",
        "    return get_biases\n",
        "\n",
        "\n",
        "def linear(input, w, b):\n",
        "    \"\"\"\n",
        "    Return linear function in TensorFlow\n",
        "    :param input: TensorFlow input\n",
        "    :param w: TensorFlow weights\n",
        "    :param b: TensorFlow biases\n",
        "    :return: TensorFlow linear function\n",
        "    \"\"\"\n",
        "    y=  tf.add(tf.matmul(input,w),b)\n",
        "    # TODO: Linear Function (xW + b)\n",
        "    \n",
        "    return y\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPd2fWE76hcj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6f07313b-406d-46f2-fcc0-d02f1db6c06b"
      },
      "cell_type": "code",
      "source": [
        "mport tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from test import *\n",
        "\n",
        "def mnist_features_labels(n_labels):\n",
        "    \"\"\"\n",
        "    Gets the first <n> labels from the MNIST dataset\n",
        "    :param n_labels: Number of labels to use\n",
        "    :return: Tuple of feature list and label list\n",
        "    \"\"\"\n",
        "    mnist_features = []\n",
        "    mnist_labels = []\n",
        "\n",
        "    mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
        "\n",
        "    # In order to make quizzes run faster, we're only looking at 10000 images\n",
        "    for mnist_feature, mnist_label in zip(*mnist.train.next_batch(10000)):\n",
        "\n",
        "        # Add features and labels if it's for the first <n>th labels\n",
        "        if mnist_label[:n_labels].any():\n",
        "            mnist_features.append(mnist_feature)\n",
        "            mnist_labels.append(mnist_label[:n_labels])\n",
        "\n",
        "    return mnist_features, mnist_labels\n",
        "\n",
        "\n",
        "# Number of features (28*28 image is 784 features)\n",
        "n_features = 784\n",
        "# Number of labels\n",
        "n_labels = 3\n",
        "\n",
        "# Features and Labels\n",
        "features = tf.placeholder(tf.float32)\n",
        "labels = tf.placeholder(tf.float32)\n",
        "\n",
        "# Weights and Biases\n",
        "w = get_weights(n_features, n_labels)\n",
        "b = get_biases(n_labels)\n",
        "\n",
        "# Linear Function xW + b\n",
        "logits = linear(features, w, b)\n",
        "\n",
        "# Training data\n",
        "train_features, train_labels = mnist_features_labels(n_labels)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "\n",
        "with tf.Session() as session:\n",
        "    # TODO: Initialize session variables\n",
        "    session.run(init)\n",
        "    # Softmax\n",
        "    prediction = tf.nn.softmax(logits)\n",
        "\n",
        "    # Cross entropy\n",
        "    # This quantifies how far off the predictions were.\n",
        "    # You'll learn more about this in future lessons.\n",
        "    cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
        "\n",
        "    # Training loss\n",
        "    # You'll learn more about this in future lessons.\n",
        "    loss = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "    # Rate at which the weights are changed\n",
        "    # You'll learn more about this in future lessons.\n",
        "    learning_rate = 0.08\n",
        "\n",
        "    # Gradient Descent\n",
        "    # This is the method used to train the model\n",
        "    # You'll learn more about this in future lessons.\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "    # Run optimizer and get loss\n",
        "    _, l = session.run(\n",
        "        [optimizer, loss],\n",
        "        feed_dict={features: train_features, labels: train_labels})\n",
        "\n",
        "# Print loss\n",
        "print('Loss: {}'.format(l))\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /datasets/ud730/mnist/train-images-idx3-ubyte.gz\n",
            "Extracting /datasets/ud730/mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting /datasets/ud730/mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting /datasets/ud730/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Loss: 15.78938102722168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NJqB7_yf9ZsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7b9fc2fd-3ac0-48e2-c8ff-503b874227d3"
      },
      "cell_type": "code",
      "source": [
        "##Grader done by Udacity\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework.errors import FailedPreconditionError\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def is_weights_good(w):\n",
        "    w_answer = [[-0.01811021,  0.51838213],\n",
        " [ 0.05832403, -0.48847285],\n",
        " [-0.37598562, -0.7711397 ],\n",
        " [-0.5922465, -0.3118519 ],\n",
        " [ 0.21055079, -1.1010232 ]] \n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        w_result = sess.run(w)\n",
        "      \n",
        "    return np.allclose(w_answer, w_result)\n",
        "\n",
        "\n",
        "def is_biases_good(b):\n",
        "    b_answer = [0.0, 0.0]\n",
        "    \n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        b_result = sess.run(b)\n",
        "        \n",
        "    return np.array_equal(b_answer, b_result)\n",
        "\n",
        "\n",
        "def is_linear_good(l, test_input):\n",
        "    \n",
        "    logits_answer = [[-2.34565091, -9.52450562],[-8.03849602, -9.28480148]]\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        logits_result = sess.run(l, feed_dict={test_input: [[1,2,3,4,5], [6,7,8,9,0]]})\n",
        "        \n",
        "    return np.allclose(logits_answer, logits_result)\n",
        "\n",
        "def get_result(get_weights, get_biases, linear):\n",
        "    result = {\n",
        "        'correct': False,\n",
        "        'feedback': 'That\\'s the wrong answer.',\n",
        "        'comment': ''}\n",
        "\n",
        "    tf.set_random_seed(123456)\n",
        "    \n",
        "    n_features = 5\n",
        "    n_labels = 2\n",
        "    test_input = tf.placeholder(tf.float32)\n",
        "    \n",
        "    weights = get_weights(n_features, n_labels)\n",
        "    biases = get_biases(n_labels)\n",
        "    lin = linear(test_input, weights, biases)\n",
        "\n",
        "    if not isinstance(weights, tf.Variable):\n",
        "        result['feedback'] = 'Function weights not returning tf.Variable type.'\n",
        "        result['comment'] = 'Use the tf.Variable function.'\n",
        "    elif not isinstance(biases, tf.Variable):\n",
        "        result['feedback'] = 'Function biases not returning tf.Variable type.'\n",
        "        result['comment'] = 'Use the tf.Variable function.'\n",
        "    elif weights.get_shape() != (n_features, n_labels):\n",
        "        result['feedback'] = 'Function weights is returning the wrong shape.'\n",
        "    elif biases.get_shape() != n_labels:\n",
        "        result['feedback'] = 'Function biases is returning the wrong shape.'\n",
        "    elif not is_weights_good(weights):\n",
        "        result['feedback'] = 'Function weights isn\\'t correct.'\n",
        "    elif not is_biases_good(biases):\n",
        "        result['feedback'] = 'Function biases isn\\'t correct.'\n",
        "    elif not is_linear_good(lin, test_input):\n",
        "        import pdb;pdb.set_trace()\n",
        "        result['feedback'] = 'Function linear isn\\'t correct.'\n",
        "    else:\n",
        "        try:\n",
        "            std_out = sys.stdout\n",
        "            f = open(os.devnull, 'w')\n",
        "            sys.stdout = f\n",
        "        \n",
        "        except FailedPreconditionError as err:\n",
        "            if err.message.startswith('Attempting to use uninitialized value Variable'):\n",
        "                result['feedback'] = 'At least one variable is not initialized.'\n",
        "            else:\n",
        "                raise err\n",
        "        else:\n",
        "            result['correct'] = True\n",
        "            result['feedback'] = 'You got it!  That\\'s the correct answer.'\n",
        "        finally:\n",
        "            sys.stdout = std_out\n",
        "    return result\n",
        "\n",
        "def run_grader(get_weights, get_biases, linear):\n",
        "    \n",
        "    try:\n",
        "    # Get grade result information\n",
        "        result = get_result(get_weights, get_biases, linear)\n",
        "    except Exception as err:\n",
        "        # Default error result\n",
        "        result = {\n",
        "            'correct': False,\n",
        "            'feedback': 'Something went wrong with your submission:',\n",
        "            'comment': str(err)}\n",
        "\n",
        "    feedback = result.get('feedback')\n",
        "    comment = result.get('comment')\n",
        "\n",
        "    print(f\"{feedback}\\n{comment}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_grader(get_weights, get_biases, linear)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function weights isn't correct.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BaCqJvDt6n8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0a0244ab-a8a9-4bb8-c2a9-555ae7a723e8"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "### DON'T MODIFY ANYTHING BELOW ###\n",
        "### Be sure to run all cells above before running this cell ###\n",
        "#import grader\n",
        "\n",
        "try:\n",
        "    run_grader(get_weights, get_biases, linear)\n",
        "except Exception as err:\n",
        "    print(str(err))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function weights isn't correct.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YM4M2_t29ypJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##############################\n",
        "#Logistic Classifier ends\n",
        "##############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "klc7atrO9Y65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##############################\n",
        "#Softmax function\n",
        "##############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3BUScLk6q4x4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d45bd1fa-60fe-45c7-d5d6-d378cf7222da"
      },
      "cell_type": "code",
      "source": [
        "# Solution is available in the other \"solution.py\" tab\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    # TODO: Compute and return softmax(x)\n",
        "    return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "    \n",
        "logits = [3.0, 1.0, 0.2]\n",
        "print(softmax(logits))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.8360188  0.11314284 0.05083836]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}